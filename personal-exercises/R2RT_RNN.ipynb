{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction**\n",
    "\n",
    "Below codes come from an excellent article from [R2RT](https://r2rt.com/recurrent-neural-networks-in-tensorflow-i.html), with detailed explanation in HOWs and WHYs in RNN implementation with TensorFlow 1.0. I learnt a lot from this article and hopefully you can as well.\n",
    "\n",
    "The most important thing to remember here is RNN introduces the concept of \"time steps\" which inherently requires specific requirements for inputs format. This is the central theme which governs the whole implementation.\n",
    "\n",
    "Below is the RNN architecture used:\n",
    "\n",
    "![RNN architecture](https://r2rt.com/static/images/BasicRNNLabeled.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 0\n",
      "Average loss at step 100 for last 250 steps: 0.634926326275\n",
      "Average loss at step 200 for last 250 steps: 0.564726597667\n",
      "Average loss at step 300 for last 250 steps: 0.561335769892\n",
      "Average loss at step 400 for last 250 steps: 0.559246102571\n",
      "Average loss at step 500 for last 250 steps: 0.554829942584\n",
      "Average loss at step 600 for last 250 steps: 0.527248063684\n",
      "Average loss at step 700 for last 250 steps: 0.520829907358\n",
      "Average loss at step 800 for last 250 steps: 0.520399137735\n",
      "Average loss at step 900 for last 250 steps: 0.520683761835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160c2e10630>]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x160c2b75ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# basic implementation\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Global configuration variables or hyperparameters\n",
    "num_steps = 5 # number of truncated backprop steps\n",
    "batch_size = 200\n",
    "num_classes = 2\n",
    "state_size = 4\n",
    "learning_rate = 0.1\n",
    "\n",
    "def gen_data(size=1000000):\n",
    "    X = np.array(np.random.choice(2, size=(size,)))\n",
    "    # X is a row vector with a length of 'size' with elements either 0 or 1\n",
    "    Y = []\n",
    "    for i in range(size):\n",
    "        threshold = 0.5\n",
    "        if X[i-3] == 1:\n",
    "            threshold += 0.5\n",
    "        if X[i-8] == 1:\n",
    "            threshold -= 0.25\n",
    "        if np.random.rand() > threshold:\n",
    "            Y.append(0)\n",
    "        else:\n",
    "            Y.append(1)\n",
    "    return X, np.array(Y)\n",
    "\n",
    "def gen_batch(raw_data, batch_size, num_steps):\n",
    "    raw_x, raw_y = raw_data\n",
    "    data_length = len(raw_x)\n",
    "    \n",
    "    # partition raw data into batches and stack them vertically in a data matrix\n",
    "    batch_partition_length = data_length // batch_size\n",
    "    data_x = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    data_y = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    for i in range(batch_size):\n",
    "        data_x[i] = raw_x[batch_partition_length * i : batch_partition_length * (i + 1)]\n",
    "        data_y[i] = raw_y[batch_partition_length * i : batch_partition_length * (i + 1)]\n",
    "        \n",
    "    # further divide each batch partition into num_steps for truncated backprop\n",
    "    epoch_size = batch_partition_length // num_steps\n",
    "    for i in range(epoch_size):\n",
    "        x = data_x[:, i * num_steps : (i + 1) * num_steps]\n",
    "        y = data_y[:, i * num_steps : (i + 1) * num_steps]\n",
    "        yield(x, y)\n",
    "        \n",
    "def gen_epochs(n, num_steps):\n",
    "    for i in range(n):\n",
    "        yield gen_batch(gen_data(), batch_size, num_steps)\n",
    "        \n",
    "# placeholders\n",
    "x = tf.placeholder(tf.int32, [batch_size, num_steps], name='inputs')\n",
    "y = tf.placeholder(tf.int32, [batch_size, num_steps], name='labels')\n",
    "init_state = tf.zeros([batch_size, state_size])\n",
    "\n",
    "# turn our x placeholder into inputs a list of one-hot encoded tensors\n",
    "# with length of num_steps, and shape [batch_size, num_classes]\n",
    "x_one_hot = tf.one_hot(x, num_classes)\n",
    "rnn_inputs = tf.unstack(x_one_hot, axis=1)\n",
    "\n",
    "\"\"\"\n",
    "Here I just want to give a visual on the above two lines to see what was going on\n",
    "In [1]:\n",
    "x = np.array([[1, 0, 0, 1], [1, 0, 1, 0], [0, 1, 0, 1]]) # batch_size=3, num_steps=4\n",
    "x_one_hot = tf.one_hot(x, 2) #num_classes=2\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(x_one_hot)) #x_one_hot.shape=(3, 4, 2)\n",
    "\n",
    "Out [1]:\n",
    "[[[ 0.  1.]\n",
    "  [ 1.  0.]\n",
    "  [ 1.  0.]\n",
    "  [ 0.  1.]]\n",
    "\n",
    " [[ 0.  1.]\n",
    "  [ 1.  0.]\n",
    "  [ 0.  1.]\n",
    "  [ 1.  0.]]\n",
    "\n",
    " [[ 1.  0.]\n",
    "  [ 0.  1.]\n",
    "  [ 1.  0.]\n",
    "  [ 0.  1.]]]\n",
    "  \n",
    "In [2]:\n",
    "rnn_inputs = tf.unstack(x_one_hot, axis=1)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(rnn_inputs)) \n",
    "# rnn_inputs is a list with a length equal to the number of time steps,\n",
    "# and each element is a Rank 2 tensor in the shape of (3, 2)\n",
    "\n",
    "Out [2]:\n",
    "[array([[ 0.,  1.],\n",
    "       [ 0.,  1.],\n",
    "       [ 1.,  0.]], dtype=float32), array([[ 1.,  0.],\n",
    "       [ 1.,  0.],\n",
    "       [ 0.,  1.]], dtype=float32), array([[ 1.,  0.],\n",
    "       [ 0.,  1.],\n",
    "       [ 1.,  0.]], dtype=float32), array([[ 0.,  1.],\n",
    "       [ 1.,  0.],\n",
    "       [ 0.,  1.]], dtype=float32)]\n",
    "\n",
    "In [3]:\n",
    "len(rnn_inputs)\n",
    "\n",
    "Out [3]:\n",
    "4\n",
    "\"\"\"\n",
    "\n",
    "with tf.variable_scope('rnn_cell'):\n",
    "    W = tf.get_variable('W', [num_classes + state_size, state_size])\n",
    "    b = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0))\n",
    "    \n",
    "def rnn_cell(rnn_input, state):\n",
    "    with tf.variable_scope('rnn_cell', reuse=True):\n",
    "        W = tf.get_variable('W', [num_classes + state_size, state_size])\n",
    "        b = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0))\n",
    "        return tf.tanh(tf.matmul(tf.concat([rnn_input, state], 1), W) + b)\n",
    "    \n",
    "\"\"\"\n",
    "Adding rnn_cell to graph\n",
    "\"\"\"\n",
    "\n",
    "state = init_state\n",
    "rnn_outputs = []\n",
    "for rnn_input in rnn_inputs:\n",
    "    # here we build a rnn with rnn_cell copied by num_steps times\n",
    "    state = rnn_cell(rnn_input, state)\n",
    "    rnn_outputs.append(state)\n",
    "final_state = rnn_outputs[-1]\n",
    "\n",
    "\"\"\"\n",
    "Predictions, loss, training step\n",
    "\"\"\"\n",
    "\n",
    "# logits and predictions\n",
    "with tf.variable_scope('softmax'):\n",
    "    W = tf.get_variable('W', [state_size, num_classes])\n",
    "    b = tf.get_variable('b', [num_classes], initializer=tf.constant_initializer(0.0))\n",
    "logits = [tf.matmul(rnn_output, W) + b for rnn_output in rnn_outputs]\n",
    "predictions = [tf.nn.softmax(logit) for logit in logits]\n",
    "\n",
    "# Turn our y placeholder into a list of labels\n",
    "y_as_list = tf.unstack(y, num=num_steps, axis=1)\n",
    "\n",
    "# losses and train_step\n",
    "losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label, logits=logit) for logit, label in zip(logits, y_as_list)]\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "train_step = tf.train.AdagradOptimizer(learning_rate).minimize(total_loss)\n",
    "\n",
    "\"\"\"\n",
    "Train the network\n",
    "\"\"\"\n",
    "\n",
    "def train_network(num_epochs, num_steps, state_size=4, verbose=True):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        training_losses = []\n",
    "        for idx, epoch in enumerate(gen_epochs(num_epochs, num_steps)):\n",
    "            training_loss = 0\n",
    "            training_state = np.zeros((batch_size, state_size))\n",
    "            if verbose:\n",
    "                print(\"\\nEPOCH\", idx)\n",
    "            for step, (X, Y) in enumerate(epoch):\n",
    "                tr_losses, training_loss_, training_state, _ = \\\n",
    "                    sess.run([losses,\n",
    "                              total_loss,\n",
    "                              final_state,\n",
    "                              train_step],\n",
    "                                  feed_dict={x: X, y: Y, init_state: training_state})\n",
    "                training_loss += training_loss_\n",
    "                if step % 100 == 0 and step > 0:\n",
    "                    if verbose:\n",
    "                        print(\"Average loss at step\", step,\n",
    "                              \"for last 250 steps:\", training_loss /100)\n",
    "                    training_losses.append(training_loss / 100)\n",
    "                    training_loss = 0\n",
    "\n",
    "    return training_losses\n",
    "\n",
    "training_losses = train_network(1,num_steps)\n",
    "plt.plot(training_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 0\n",
      "Average loss at step 100 for last 250 steps: 0.628054853082\n",
      "Average loss at step 200 for last 250 steps: 0.536067923307\n",
      "Average loss at step 300 for last 250 steps: 0.523046225905\n",
      "Average loss at step 400 for last 250 steps: 0.52222602427\n",
      "Average loss at step 500 for last 250 steps: 0.518991369605\n",
      "Average loss at step 600 for last 250 steps: 0.521843917966\n",
      "Average loss at step 700 for last 250 steps: 0.520809316337\n",
      "Average loss at step 800 for last 250 steps: 0.52087038964\n",
      "Average loss at step 900 for last 250 steps: 0.522309147418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d265aafa20>]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfhGREqPgFxEpMQp+EZESo+AXESkx/x/FN4ptjR2LXAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d2657c36d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Improved version with TensorFlow's dynamic_rnn API\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Global configuration variables or hyperparameters\n",
    "num_steps = 5 # number of truncated backprop steps\n",
    "batch_size = 200\n",
    "num_classes = 2\n",
    "state_size = 4\n",
    "learning_rate = 0.1\n",
    "\n",
    "def gen_data(size=1000000):\n",
    "    X = np.array(np.random.choice(2, size=(size,)))\n",
    "    # X is a row vector with a length of 'size' with elements either 0 or 1\n",
    "    Y = []\n",
    "    for i in range(size):\n",
    "        threshold = 0.5\n",
    "        if X[i-3] == 1:\n",
    "            threshold += 0.5\n",
    "        if X[i-8] == 1:\n",
    "            threshold -= 0.25\n",
    "        if np.random.rand() > threshold:\n",
    "            Y.append(0)\n",
    "        else:\n",
    "            Y.append(1)\n",
    "    return X, np.array(Y)\n",
    "\n",
    "def gen_batch(raw_data, batch_size, num_steps):\n",
    "    raw_x, raw_y = raw_data\n",
    "    data_length = len(raw_x)\n",
    "    \n",
    "    # partition raw data into batches and stack them vertically in a data matrix\n",
    "    batch_partition_length = data_length // batch_size\n",
    "    data_x = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    data_y = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    for i in range(batch_size):\n",
    "        data_x[i] = raw_x[batch_partition_length * i : batch_partition_length * (i + 1)]\n",
    "        data_y[i] = raw_y[batch_partition_length * i : batch_partition_length * (i + 1)]\n",
    "        \n",
    "    # further divide each batch partition into num_steps for truncated backprop\n",
    "    epoch_size = batch_partition_length // num_steps\n",
    "    for i in range(epoch_size):\n",
    "        x = data_x[:, i * num_steps : (i + 1) * num_steps]\n",
    "        y = data_y[:, i * num_steps : (i + 1) * num_steps]\n",
    "        yield(x, y)\n",
    "        \n",
    "def gen_epochs(n, num_steps):\n",
    "    for i in range(n):\n",
    "        yield gen_batch(gen_data(), batch_size, num_steps)\n",
    "        \n",
    "# placeholders\n",
    "x = tf.placeholder(tf.int32, [batch_size, num_steps], name='inputs')\n",
    "y = tf.placeholder(tf.int32, [batch_size, num_steps], name='labels')\n",
    "init_state = tf.zeros([batch_size, state_size])\n",
    "\n",
    "# turn our x placeholder into inputs with the shape of (batch_size, num_steps, num_classes)\n",
    "rnn_inputs = tf.one_hot(x, num_classes)\n",
    "\n",
    "cell = tf.contrib.rnn.BasicRNNCell(state_size)\n",
    "rnn_outputs, final_state = tf.nn.dynamic_rnn(cell, rnn_inputs, initial_state=init_state)\n",
    "\n",
    "# these two lines above replace a whole bunch of codes quoted below from the previous implementation\n",
    "# one common thing to notice with these API is you do not need to define paramaters anymore\n",
    "\n",
    "\"\"\"\n",
    "with tf.variable_scope('rnn_cell'):\n",
    "    W = tf.get_variable('W', [num_classes + state_size, state_size])\n",
    "    b = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0))\n",
    "    \n",
    "def rnn_cell(rnn_input, state):\n",
    "    with tf.variable_scope('rnn_cell', reuse=True):\n",
    "        W = tf.get_variable('W', [num_classes + state_size, state_size])\n",
    "        b = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0))\n",
    "        return tf.tanh(tf.matmul(tf.concat([rnn_input, state], 1), W) + b)\n",
    "\n",
    "state = init_state\n",
    "rnn_outputs = []\n",
    "for rnn_input in rnn_inputs:\n",
    "    # here we build a rnn with rnn_cell copied by num_steps times\n",
    "    state = rnn_cell(rnn_input, state)\n",
    "    rnn_outputs.append(state)\n",
    "final_state = rnn_outputs[-1]\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Predictions, loss, training step\n",
    "\"\"\"\n",
    "\n",
    "# logits and predictions\n",
    "with tf.variable_scope('softmax'):\n",
    "    W = tf.get_variable('W', [state_size, num_classes])\n",
    "    b = tf.get_variable('b', [num_classes], initializer=tf.constant_initializer(0.0))\n",
    "logits = tf.reshape(tf.matmul(tf.reshape(rnn_outputs, [-1, state_size]), W) + b, [batch_size, num_steps, num_classes])\n",
    "predictions = tf.nn.softmax(logits)\n",
    "\n",
    "\n",
    "# losses and train_step\n",
    "# here y can be feeded altogether\n",
    "losses = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "train_step = tf.train.AdagradOptimizer(learning_rate).minimize(total_loss)\n",
    "\n",
    "\"\"\"\n",
    "Train the network\n",
    "\"\"\"\n",
    "\n",
    "def train_network(num_epochs, num_steps, state_size=4, verbose=True):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        training_losses = []\n",
    "        for idx, epoch in enumerate(gen_epochs(num_epochs, num_steps)):\n",
    "            training_loss = 0\n",
    "            training_state = np.zeros((batch_size, state_size))\n",
    "            if verbose:\n",
    "                print(\"\\nEPOCH\", idx)\n",
    "            for step, (X, Y) in enumerate(epoch):\n",
    "                tr_losses, training_loss_, training_state, _ = \\\n",
    "                    sess.run([losses,\n",
    "                              total_loss,\n",
    "                              final_state,\n",
    "                              train_step],\n",
    "                                  feed_dict={x:X, y:Y, init_state:training_state})\n",
    "                training_loss += training_loss_\n",
    "                if step % 100 == 0 and step > 0:\n",
    "                    if verbose:\n",
    "                        print(\"Average loss at step\", step,\n",
    "                              \"for last 250 steps:\", training_loss/100)\n",
    "                    training_losses.append(training_loss/100)\n",
    "                    training_loss = 0\n",
    "\n",
    "    return training_losses\n",
    "\n",
    "training_losses = train_network(1,num_steps)\n",
    "plt.plot(training_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
